{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os, re, sys, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import inspect\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# Define a function to see the source code of a function. \n",
    "def showfunc(functiontoshow):\n",
    "    print(inspect.getsource(functiontoshow))\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "import typhon as tp\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# Assume WGS 1984 for the reference Ellipsoid.\n",
    "R_eq = 6378137 # Earth's equatorial radius, in meters\n",
    "iFlttn = 298.257223563 # Inverse flattening\n",
    "R_polar = R_eq * (1-1/iFlttn) # Earth's polar radius\n",
    "eccnty = (2/iFlttn - (1/iFlttn)**2)**0.5 # Eccentricity of the ellipsoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[6]:\n",
    "\n",
    "\n",
    "# Read in radimeters data. \n",
    "\n",
    "# Functions for reading in radiometers data. Written by Dr. Choi. \n",
    "class radiometrics:\n",
    "    def read_lv0_data(self,f, *args):\n",
    "\n",
    "        if not f:\n",
    "            print(\"Missing argument FN, Please provide input filename.\")\n",
    "        if len(args) == 0:\n",
    "            tmp_dir = os.path.dirname(f)\n",
    "            dat_idx = '15'\n",
    "        else:\n",
    "            if len(args) == 1:\n",
    "                dat_idx = args[0]\n",
    "                tmp_dir = os.path.dirname(f)\n",
    "            else:\n",
    "                dat_idx = args[0]\n",
    "                tmp_dir = args[1]\n",
    "\n",
    "        dain = os.path.dirname(f)\n",
    "        fn = os.path.basename(f)\n",
    "\n",
    "        fn_sep = re.split('[. _]', fn)\n",
    "        if fn_sep[2] != 'lv0':\n",
    "            print(\"=============================================================================\")\n",
    "            print(\" Given file is not Level2 data. Please try again with lv0 file. Returning...\")\n",
    "            print(\"=============================================================================\")\n",
    "            return -1\n",
    "\n",
    "        f1 = \"_\".join(fn_sep[:len(fn_sep)-1]) + \"_{0}\".format( dat_idx ) + \".csv\"\n",
    "        file_exists = os.path.isfile( os.path.join(dain, f1) )\n",
    "        print(file_exists) \n",
    "        if not file_exists:\n",
    "            bsmwr = radiometrics()\n",
    "            bsmwr.prepare_original(f)\n",
    "\n",
    "        fin = os.path.join(dain, f1)\n",
    "\n",
    "        delimiters = (\"+\", \"-\", \"%\", \"/\", '|', \":\", \" \", \"(\", \")\")\n",
    "        # Get headers (column titles)\n",
    "        regexPattern = '|'.join(map(re.escape, delimiters))\n",
    "        with open( fin, 'r' ) as d:\n",
    "                line = d.readline()     # Read the first line in file\n",
    "                h0 = re.split(',|\\n', line)\n",
    "        d.close()\n",
    "        # Read data\n",
    "        df = pd.read_csv(fin, skiprows=1,names=h0)\n",
    "\n",
    "        # Make time understood in Pandas\n",
    "        df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"], format='%m/%d/%Y %H:%M:%S', utc=True)\n",
    "\n",
    "        self.df = df\n",
    "        return df\n",
    "\n",
    "    def read_lv1_data(self,f, *args):\n",
    "\n",
    "        if not f:\n",
    "            print(\"Missing argument FN, Please provide input filename.\")\n",
    "        if len(args) == 0:\n",
    "            tmp_dir = os.path.dirname(f)\n",
    "            dat_idx = '50'\n",
    "        else:\n",
    "            if len(args) == 1:\n",
    "                dat_idx = args[0]\n",
    "                tmp_dir = os.path.dirname(f)\n",
    "            else:\n",
    "                dat_idx = args[0]\n",
    "                tmp_dir = args[1]\n",
    "\n",
    "        dain = os.path.dirname(f)\n",
    "        fn = os.path.basename(f)\n",
    "\n",
    "        fn_sep = re.split('[. _]', fn)\n",
    "        if fn_sep[2] != 'lv1':\n",
    "            print(\"=============================================================================\")\n",
    "            print(\" Given file is not Level2 data. Please try again with lv1 file. Returning...\")\n",
    "            print(\"=============================================================================\")\n",
    "            return -1\n",
    "\n",
    "        f1 = \"_\".join(fn_sep[:len(fn_sep)-1]) + \"_{0}\".format( dat_idx ) + \".csv\"\n",
    "        file_exists = os.path.isfile( os.path.join(dain, f1) )\n",
    "        print(file_exists) \n",
    "        if not file_exists:\n",
    "            bsmwr = radiometrics()\n",
    "            bsmwr.prepare_original(f)\n",
    "\n",
    "        fin = os.path.join(dain, f1)\n",
    "\n",
    "        delimiters = (\"+\", \"-\", \"%\", \"/\", '|', \":\", \" \", \"(\", \")\")\n",
    "        # Get headers (column titles)\n",
    "        regexPattern = '|'.join(map(re.escape, delimiters))\n",
    "        with open( fin, 'r' ) as d:\n",
    "                line = d.readline()     # Read the first line in file\n",
    "                h0 = re.split(',|\\n', line)\n",
    "        d.close()\n",
    "        # Read data\n",
    "        df = pd.read_csv(fin, skiprows=1,names=h0)\n",
    "\n",
    "        # Make time understood in Pandas\n",
    "        df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"], format='%m/%d/%y %H:%M:%S', utc=True)\n",
    "\n",
    "        self.df = df\n",
    "        return df\n",
    "\n",
    "    def read_lv2_data(self,f,*args):\n",
    "\n",
    "        if not f:\n",
    "            print(\"Missing argument FN, Please provide input filename.\")\n",
    "        if len(args) == 0:\n",
    "            tmp_dir = os.path.dirname(f)\n",
    "            dat_idx = '400'\n",
    "        else:\n",
    "            if len(args) == 1:\n",
    "                dat_idx = args[0]\n",
    "                tmp_dir = os.path.dirname(f)\n",
    "            else:\n",
    "                dat_idx = args[0]\n",
    "                tmp_dir = args[1]\n",
    "\n",
    "        dain = os.path.dirname(f)\n",
    "        fn = os.path.basename(f)\n",
    "\n",
    "        fn_sep = re.split('[. _]', fn)\n",
    "        if fn_sep[2] != 'lv2':\n",
    "            print(\"=============================================================================\")\n",
    "            print(\" Given file is not Level2 data. Please try again with lv2 file. Returning...\")\n",
    "            print(\"=============================================================================\")\n",
    "            return -1\n",
    "\n",
    "        f1 = \"_\".join(fn_sep[:len(fn_sep)-1]) + \"_{0}\".format( dat_idx ) + \".csv\"\n",
    "        file_exists = os.path.isfile( os.path.join(dain, f1) )\n",
    "        print(file_exists) \n",
    "        if not file_exists:\n",
    "            bsmwr = radiometrics()\n",
    "            bsmwr.prepare_original(f)\n",
    "\n",
    "        fin = os.path.join(dain, f1)\n",
    "\n",
    "        delimiters = (\"+\", \"-\", \"%\", \"/\", '|', \":\", \" \", \"(\", \")\")\n",
    "        # Get headers (column titles)\n",
    "        regexPattern = '|'.join(map(re.escape, delimiters))\n",
    "        with open( fin, 'r' ) as d:\n",
    "                line = d.readline()     # Read the first line in file\n",
    "                h0 = re.split(',|\\n', line)\n",
    "        d.close()\n",
    "        # Read data\n",
    "        df = pd.read_csv(fin, skiprows=1,names=h0)\n",
    "\n",
    "        # Make time understood in Pandas\n",
    "        df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"], format='%m/%d/%y %H:%M:%S', utc=True)\n",
    "\n",
    "        self.df = df\n",
    "        return df\n",
    "    \n",
    "    def prepare_original(self, fn, *args):\n",
    "\n",
    "        if not fn:\n",
    "            print(\"Missing argument FN, Please provide input filename.\")\n",
    "        if len(args) == 0:\n",
    "            tmp_dir = os.path.dirname(fn)\n",
    "        else:\n",
    "            tmp_dir = args[0]\n",
    "        fn_sep = fn.split(\".\")\n",
    "\n",
    "        dataidx = []\n",
    "        datanum = []\n",
    "        delimiters = (\"+\", \"-\", \"%\", \"/\", '|', \":\", \" \", \"(\", \")\")\n",
    "        regexPattern = '|'.join(map(re.escape, delimiters))\n",
    "        with open( fn, 'r' ) as d:\n",
    "            while True:\n",
    "                line = d.readline()     # Read the first line in file\n",
    "                if not line: \n",
    "                    self.dataidx = [0]\n",
    "                    return dataidx\n",
    "                    break\n",
    "                h0 = re.split(',|\\n', line)\n",
    "                nh = len( h0 ) - 1      # Number of headers. Ignore last header since it's '/n'\n",
    "                # \n",
    "                # Remove inappropriate letters for BIN filename\n",
    "                # \n",
    "                h1 = [ \"\".join( re.split(regexPattern, h0[i]) ) for i in range(0,nh) ]\n",
    "                                        #---------------------------\n",
    "                if h1[0] == \"Record\":   # Header for each data type\n",
    "                                        #---------------------------\n",
    "                    dataidx.append( h1[2] )\n",
    "                    datanum.append(1)\n",
    "\n",
    "                    foun = \".\".join(fn_sep[:len(fn_sep)-1]) + \"_{0}\".format( h1[2] ) + '.csv'\n",
    "                    fou = open( os.path.join(tmp_dir, foun), 'w' )                     # Open input file\n",
    "                    fou.write( \",\".join(h1) + \"\\n\" )                                # Write data (Add \\n for new line\n",
    "                    fou.close()                                                     # Close input file\n",
    "                                        #-------------------------\n",
    "                else:                   # Data for each data type\n",
    "                                        #-------------------------\n",
    "                    if h1[2] == '99':\n",
    "                        if dataidx.count('99') == 0:\n",
    "                            dataidx.append( h1[2] )\n",
    "                            datanum.append(1)\n",
    "                            file_op_index = 'w'\n",
    "                        else:\n",
    "                            datanum[dataidx.index('99')] = datanum[dataidx.index('99')] + 1\n",
    "                            file_op_index = 'a'\n",
    "\n",
    "                            foun = \".\".join(fn_sep[:len(fn_sep)-1]) + \"_{0}\".format( \"99\" ) + '.csv'\n",
    "                            fou = open( os.path.join(tmp_dir, foun), file_op_index )   # Open input file\n",
    "                            fou.write( line )                                       # Write data\n",
    "                            fou.close()                                             # Close input file\n",
    "                    else:\n",
    "                        for i in range( 0, len(dataidx) ):\n",
    "                            line_index = int(h1[2])\n",
    "                            data_index = int(dataidx[i])\n",
    "                            if (line_index > data_index and line_index <= data_index + 5):\n",
    "                                #\n",
    "                                # There are types of data line ends with comma(,), which Python code recognise\n",
    "                                # as null('') at re.split. In this case, comma separated array shows one more\n",
    "                                # elements than it should. If last element of comma separated array contains\n",
    "                                # null(''), it should drop as bellow. \n",
    "                                #\n",
    "                                h1len = len(h1)\n",
    "                                if h1[h1len-1] == '':\n",
    "                                    h1 = h1[0:h1len-1]\n",
    "                                    nh = nh - 1\n",
    "\n",
    "                                datanum[dataidx.index(dataidx[i])] = datanum[dataidx.index(dataidx[i])] + 1\n",
    "\n",
    "                                foun = \".\".join(fn_sep[:len(fn_sep)-1]) + \"_{0}\".format( dataidx[i] ) + '.csv'\n",
    "                                fou = open( os.path.join(tmp_dir, foun), 'a' )         # Open input file\n",
    "                                fou.write( line )                                   # Write data\n",
    "                                fou.close()                                         # Close input file\n",
    "\n",
    "        d.close()\n",
    "        self.dataidx = dataidx\n",
    "        return dataidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in ['03', '04', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16']:\n",
    "    for hour in ['00', '03', '06', '09', '12', '15', '18', '21']:\n",
    "\n",
    "        # In[5]:\n",
    "\n",
    "\n",
    "        # Data month and day\n",
    "        dada = '07-' + day\n",
    "\n",
    "        # Data hour of day\n",
    "        daho = hour\n",
    "\n",
    "        # Files location\n",
    "        dain = os.path.join(os.getcwd(),dada)\n",
    "\n",
    "        # Observation/simulation time\n",
    "        TimeOfInterest = pd.Timestamp('2018-' + dada + ' ' + daho + ':00:00+0000',tz='UTC')\n",
    "\n",
    "\n",
    "        # In[7]:\n",
    "\n",
    "\n",
    "        # Read in brightness temperature data, contained in Level1 data.\n",
    "        f_radmtr_lv1 = glob.glob(dain + '/*lv1.csv')[0]\n",
    "        df_radmtr_lv1 = radiometrics()\n",
    "        df_radmtr_lv1.read_lv1_data(f_radmtr_lv1)\n",
    "\n",
    "        # Radiometer channels\n",
    "        radmtr_channels = df_radmtr_lv1.df.loc[:,'Ch22.000':'Ch58.800'].dropna(axis=1).columns.str.replace('Ch','')\n",
    "        radmtr_channels = radmtr_channels.values.astype(np.float64) * 1e9\n",
    "\n",
    "\n",
    "        # In[8]:\n",
    "\n",
    "\n",
    "        # Radiometer observations (brightness temperatures) for the specific time \n",
    "        BosungObs_radmtr = df_radmtr_lv1.df.loc[(df_radmtr_lv1.df.DateTime - TimeOfInterest).abs().idxmin()]\n",
    "        print(BosungObs_radmtr.DateTime)\n",
    "        BosungObs_radmtr = BosungObs_radmtr.loc['Ch22.000':'Ch58.800'].dropna().values.flatten()\n",
    "\n",
    "\n",
    "        # In[9]:\n",
    "\n",
    "\n",
    "        # Save as .xml files. \n",
    "        tp.arts.xml.save(radmtr_channels, './ClearSky_1D_f_grid.xml')\n",
    "        tp.arts.xml.save(BosungObs_radmtr, './BosungObservations.xml')\n",
    "\n",
    "\n",
    "        # In[10]:\n",
    "\n",
    "\n",
    "        # Bosung radiometer's Gaussian optical antenna characteristics. \n",
    "\n",
    "        # Full width at half maximum:\n",
    "        FWHM_22GHz = 6.3 ;\n",
    "        FWHM_30GHz = 4.9 ;\n",
    "        FWHM_51GHz = 2.5 ;\n",
    "        FWHM_59GHz = 2.4 ;\n",
    "        # Linear interpolation\n",
    "        FWHM_22to30GHz = np.interp(radmtr_channels[0:8], np.array([22, 30])*1e9, [FWHM_22GHz, FWHM_30GHz]) ;\n",
    "        FWHM_51to59GHz = np.interp(radmtr_channels[8:22], np.array([51, 59])*1e9, [FWHM_51GHz, FWHM_59GHz]) ;\n",
    "        FWHM = np.append(FWHM_22to30GHz, FWHM_51to59GHz)\n",
    "\n",
    "        # Antenna response\n",
    "        xwidth_si = 3; # Default value in ARTS. See \"antenna_responseGaussian\".\n",
    "        dx_si = 0.1; # Default values in ARTS. See \"antenna_responseGaussian\".\n",
    "        Zenith_angle = np.arange(-xwidth_si, xwidth_si + dx_si, dx_si) * FWHM_22GHz / (2*(2*np.log(2))**0.5)\n",
    "        anthenna_response = np.zeros((1, len(radmtr_channels), len(Zenith_angle), 1))\n",
    "        for i in range(len(radmtr_channels)):\n",
    "            std_FWHM = FWHM[i]/(2*(2*np.log(2))**0.5)\n",
    "            anthenna_response[0,i,:,0] = 1/(std_FWHM*(2*np.pi)**0.5)*np.exp(-4*np.log(2)*Zenith_angle**2/(FWHM[i]**2))\n",
    "\n",
    "        # Define ARTS variable \"mblock_dlos_grid\". \n",
    "        mblock_dlos_grid = np.array([np.linspace(Zenith_angle[0],Zenith_angle[len(Zenith_angle)-1],20)]).T\n",
    "\n",
    "\n",
    "        # In[11]:\n",
    "\n",
    "\n",
    "        # Save antenna_response as GriddedField4 .xml file. \n",
    "        antenna_response_GF4 = tp.arts.griddedfield.GriddedField4()\n",
    "        antenna_response_GF4.name = 'Antenna response'\n",
    "        antenna_response_GF4.data = anthenna_response\n",
    "        antenna_response_GF4.grids = [['NaN'], radmtr_channels, Zenith_angle, np.array([0])]\n",
    "        antenna_response_GF4.gridnames = ['Polarisation', 'Frequency', 'Zenith angle', 'Azimuth angle']\n",
    "        tp.arts.xml.save(antenna_response_GF4, './ClearSky_1D_antenna_response.xml')\n",
    "\n",
    "        # Save mblock_dlos_grid as .xml file. \n",
    "        tp.arts.xml.save(mblock_dlos_grid, './ClearSky_1D_mblock_dlos_grid.xml')\n",
    "\n",
    "\n",
    "        # In[12]:\n",
    "\n",
    "\n",
    "        # Sensor LOS and geolocation \n",
    "        tp.arts.xml.save(np.array([[0]]), './ClearSky_1D_sensor_los.xml')\n",
    "        tp.arts.xml.save(np.array([[0]]), './ClearSky_1D_sensor_pos.xml')\n",
    "\n",
    "\n",
    "        # In[13]:\n",
    "\n",
    "\n",
    "        # Read in LDAPS data. \n",
    "\n",
    "        # Pressure (pres) data\n",
    "        fn_pres = \"ldps_v070_erlo_pres_BSWO_h000.\" + TimeOfInterest.strftime('%Y%m%d%H') + \".txt\"\n",
    "        f_pres = os.path.join(dain,fn_pres)\n",
    "        df_pres = pd.read_csv(f_pres, skiprows=0, \n",
    "                         names=['Index', '?(GridPosition)', 'Type', 'Pressure', 'Longitude', 'Latitude', 'Value'], \n",
    "                         sep=' mb:lon=|,lat=|,val=|:', \n",
    "                         engine='python')\n",
    "        pres_P = df_pres.loc[df_pres.Type=='HGT'].Pressure.values * 100\n",
    "        pres_GH = df_pres.loc[df_pres.Type=='HGT'].Value.values\n",
    "        pres_T = df_pres.loc[df_pres.Type=='TMP'].Value.values\n",
    "        pres_RH = df_pres.loc[df_pres.Type=='RH'].Value.values\n",
    "        pres_Lat = df_pres.Latitude[0]\n",
    "\n",
    "        # Surface (unis) data\n",
    "        fn_unis = \"ldps_v070_erlo_unis_BSWO_h000.\" + TimeOfInterest.strftime('%Y%m%d%H') + \".txt\"\n",
    "        f_unis = os.path.join(dain,fn_unis)\n",
    "        df_unis = pd.read_csv(f_unis, skiprows=0, \n",
    "                         names=['Index', '?(GridPosition)', 'Type', 'Altitude', 'Longitude', 'Latitude', 'Value'], \n",
    "                         sep=':lon=|,lat=|,val=|:',\n",
    "                         engine='python')\n",
    "        unis_P = df_unis.loc[df_unis.Type=='PRMSL'].Value.values # df_unis.loc[df_unis.Type=='PRES'].Value.values\n",
    "        unis_T = df_unis.loc[(df_unis.Type=='TMP') & (df_unis.Altitude=='surface')].Value.values\n",
    "        unis_RH = df_unis.loc[df_unis.Type=='RH'].Value.values\n",
    "        unis_Alt = 0 # df_unis.loc[df_unis.Type=='DIST'].Value.values\n",
    "\n",
    "\n",
    "        # In[14]:\n",
    "\n",
    "\n",
    "        # Pressure\n",
    "\n",
    "        # Combine the unis and pres variables. \n",
    "        LDAPS_p = np.append(unis_P, pres_P)\n",
    "        LDAPS_p\n",
    "\n",
    "\n",
    "        # In[15]:\n",
    "\n",
    "\n",
    "        # Altitude\n",
    "\n",
    "        # Convert geopotential height to geometric height. \n",
    "        # Reference (accessed 2018-07-02): \n",
    "        # http://glossary.ametsoc.org/wiki/Geopotential_height\n",
    "        # http://glossary.ametsoc.org/wiki/Acceleration_of_gravity \n",
    "        g0 = 9.80665 # Standard gravity at sea level \n",
    "        g_lat = 0.01*(980.6160*(\n",
    "            1 - 0.0026373*np.cos(np.pi/180 * 2*pres_Lat) + 0.0000059*(\n",
    "                np.cos(np.pi/180 * 2*pres_Lat)**2))) # Sea-level gravity at given latitude\n",
    "        Cg = 0.01*(3.085462*(10**-4) + 2.27*(10**-7)*np.cos(np.pi/180*2*pres_Lat)) # The coefficient in the gravity equation. \n",
    "\n",
    "        # Solve for geometric height, using the quadratic formula.\n",
    "        a = Cg/2\n",
    "        b = -g_lat\n",
    "        c = g0*pres_GH\n",
    "        pres_Alt = (-b - (b**2 - 4*a*c)**0.5)/(2*a)\n",
    "        # Here, the geopotential height is given based on 국지예보모델, so the calculated z field may be based on a spherical coordinates system.\n",
    "        # ARTS requires z field that is defined in terms of the geometrical altitude, \n",
    "        # which is the distance between the ellipsoid's surface and the point along the line passing through the Earth's center and the point. \n",
    "        # For now, assume that the difference between the two systems in this regard is negligible. \n",
    "\n",
    "        # Combine the unis and pres variables. \n",
    "        LDAPS_z = np.append(unis_Alt, pres_Alt)\n",
    "        LDAPS_z\n",
    "\n",
    "\n",
    "        # In[16]:\n",
    "\n",
    "\n",
    "        # Temperature\n",
    "\n",
    "        # Combine the unis and pres variables.\n",
    "        LDAPS_t = np.append(unis_T, pres_T)\n",
    "        LDAPS_t\n",
    "\n",
    "\n",
    "        # In[17]:\n",
    "\n",
    "\n",
    "        # Water VMR\n",
    "\n",
    "        # Combine the unis and pres variables.\n",
    "        LDAPS_RH = np.append(unis_RH, pres_RH)\n",
    "\n",
    "        # Convert RH to VMR. \n",
    "        LDAPS_watervmr = tp.physics.relative_humidity2vmr(LDAPS_RH * 0.01, LDAPS_p, LDAPS_t)\n",
    "        LDAPS_watervmr\n",
    "\n",
    "\n",
    "        # In[18]:\n",
    "\n",
    "\n",
    "        # Get rid of invalid values at the pressure levels higher than the surface pressure. \n",
    "        flag_validpressurelevels = (LDAPS_p <= LDAPS_p[0])\n",
    "        LDAPS_p = LDAPS_p[flag_validpressurelevels]\n",
    "        LDAPS_z = LDAPS_z[flag_validpressurelevels]\n",
    "        LDAPS_t = LDAPS_t[flag_validpressurelevels]\n",
    "        LDAPS_watervmr = LDAPS_watervmr[flag_validpressurelevels]\n",
    "\n",
    "\n",
    "        # In[19]:\n",
    "\n",
    "\n",
    "        # Read in radiosondes data. \n",
    "\n",
    "        fn_radsnd = \"UPP_LV2_RS92-SGP_47258_\" + TimeOfInterest.strftime('%Y%m%d%H%M') + \".txt\"\n",
    "        f_radsnd = os.path.join(dain,fn_radsnd)\n",
    "        df_radsnd = pd.read_csv(f_radsnd, sep=\",\")\n",
    "        #print(*df_radsnd.time.values, sep='\\n') # Print all values.\n",
    "        #print(df_radsnd.columns) % Data types. \n",
    "        #print(df_radsnd.loc[1865:1868]) # Pressure duplicates\n",
    "\n",
    "        # Solicit useful variables. \n",
    "        df_radsnd_useful = df_radsnd[['HGT', 'time', 'P', 'Temp', 'RH', 'MixR', 'Lon', 'Lat', 'Alt']]\n",
    "        df_radsnd_useful = df_radsnd_useful.dropna().reset_index().drop('index',axis=1)\n",
    "        df_radsnd_useful.loc[1:,] = df_radsnd_useful.loc[1:,].astype(float).values \n",
    "        df_radsnd_useful_size = len(df_radsnd_useful.loc[:,'P'])\n",
    "\n",
    "\n",
    "        # In[20]:\n",
    "\n",
    "\n",
    "        # Interpolate the data to fewer vertical grids. Use the nearest neighbor interpolation.\n",
    "        df_radsnd_useful_interp_size = 50;\n",
    "        df_radsnd_useful_interp = pd.DataFrame( \n",
    "            {'P' : \n",
    "             np.linspace(df_radsnd_useful.loc[1,'P'], df_radsnd_useful.loc[df_radsnd_useful_size-1,'P'], df_radsnd_useful_interp_size)} )\n",
    "        df_radsnd_useful_interp = df_radsnd_useful_interp.reindex(df_radsnd_useful.columns, axis=1)\n",
    "\n",
    "        # Interpolation\n",
    "        for i in range(df_radsnd_useful_interp_size):\n",
    "            nearneigindex = (df_radsnd_useful.loc[1:,'P'] - df_radsnd_useful_interp.loc[i,'P']).astype(float).abs().idxmin()\n",
    "            df_radsnd_useful_interp.loc[i,] = df_radsnd_useful.loc[nearneigindex,].astype('float')\n",
    "\n",
    "        # Unit conversions\n",
    "        df_radsnd_useful_interp.loc[:,'P'] = df_radsnd_useful_interp.loc[:,'P'] * 100\n",
    "        df_radsnd_useful_interp.loc[:,'Temp'] = df_radsnd_useful_interp.loc[:,'Temp'] + 273.15\n",
    "        df_radsnd_useful_interp.loc[:,'RH'] = df_radsnd_useful_interp.loc[:,'RH'] * 1e-2\n",
    "\n",
    "\n",
    "        # In[21]:\n",
    "\n",
    "\n",
    "        # Necessary variables for ARTS simulations \n",
    "        radsnd_P = df_radsnd_useful_interp.loc[:,'P'].values\n",
    "        radsnd_T = df_radsnd_useful_interp.loc[:,'Temp'].values\n",
    "        radsnd_WaterVMR = tp.physics.relative_humidity2vmr(df_radsnd_useful_interp.loc[:,'RH'].values, radsnd_P, radsnd_T)\n",
    "        radsnd_HGT = df_radsnd_useful_interp.loc[:,'HGT'].values\n",
    "\n",
    "\n",
    "        # In[23]:\n",
    "\n",
    "\n",
    "        # Visualize the LDAPS and radiosondes data. \n",
    "        plt.figure()\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(radsnd_T, radsnd_HGT, LDAPS_t, LDAPS_z)\n",
    "        plt.xlabel('Temperature (K)')\n",
    "        plt.ylabel('Altitude (m)')\n",
    "        #plt.ylabel('Pressure (Pa)')\n",
    "        #plt.gca().invert_yaxis()\n",
    "        plt.legend(['Radiosonde Temperature', 'LDAPS Temperature'])\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(radsnd_WaterVMR, radsnd_HGT, LDAPS_watervmr, LDAPS_z)\n",
    "        plt.xlabel('Volume mixing ratio')\n",
    "        plt.ylabel('Altitude (m)')\n",
    "        #plt.ylabel('Pressure (Pa)')\n",
    "        #plt.gca().invert_yaxis()\n",
    "        plt.legend(['Radiosonde Water VMR', 'LDAPS Water VMR'])\n",
    "\n",
    "        plt.gcf().set_size_inches(16,10)\n",
    "\n",
    "        # Save the figure.\n",
    "        plt.savefig(TimeOfInterest.strftime('%Y_%m_%d_%H-%M-%S_') + 'T&WaterVMR' + '.png')\n",
    "\n",
    "\n",
    "        # In[24]:\n",
    "\n",
    "\n",
    "        # ARTS forward model with the radiosonde data.\n",
    "        # Save the radiosonde variables as the input atmopsheric profiles. \n",
    "\n",
    "        # Save pressure grid as .xml files.\n",
    "        tp.arts.xml.save(radsnd_P, './ClearSky_1D_p_grid.xml')\n",
    "\n",
    "        # Save z_field as GriddedField3 xml file. \n",
    "        z_field_GF3 = tp.arts.griddedfield.GriddedField3()\n",
    "        z_field_GF3.data = np.reshape(radsnd_HGT,(len(radsnd_P),1,1))\n",
    "        z_field_GF3.grids = [radsnd_P, np.array([0]), np.array([0])]\n",
    "        z_field_GF3.gridnames = ['Pressure', 'Latitude', 'Longitude']\n",
    "        tp.arts.xml.save(z_field_GF3, './ClearSky_1D.z.xml')\n",
    "\n",
    "        # Save t_field as GriddedField3 xml file. \n",
    "        # Remove temperature values greater than 300 K, due to partition functions error in ARTS. \n",
    "        # radsnd_T[radsnd_T > 300] = 300\n",
    "        t_field_GF3 = tp.arts.griddedfield.GriddedField3()\n",
    "        t_field_GF3.data = np.reshape(radsnd_T,(len(radsnd_P),1,1))\n",
    "        t_field_GF3.grids = [radsnd_P, np.array([0]), np.array([0])]\n",
    "        t_field_GF3.gridnames = ['Pressure', 'Latitude', 'Longitude']\n",
    "        tp.arts.xml.save(t_field_GF3, './ClearSky_1D.t.xml')\n",
    "\n",
    "        # Save Water VMR as GriddedField3 xml file. \n",
    "        VMR_H2O_GF3 = tp.arts.griddedfield.GriddedField3()\n",
    "        VMR_H2O_GF3.data = np.reshape(radsnd_WaterVMR,(len(radsnd_P),1,1))\n",
    "        VMR_H2O_GF3.grids = [radsnd_P, np.array([0]), np.array([0])]\n",
    "        VMR_H2O_GF3.gridnames = ['Pressure', 'Latitude', 'Longitude']\n",
    "        tp.arts.xml.save(VMR_H2O_GF3, './ClearSky_1D.H2O.xml')\n",
    "\n",
    "        # Run ARTS. \n",
    "        tp.arts.run_arts(controlfile='./ClearSky_1D_ARTSvdev.arts');\n",
    "\n",
    "        # ARTS forward model results. \n",
    "        Tb_radsnd = tp.arts.xml.load(\"./ClearSky_1D_Tb.xml\")\n",
    "\n",
    "\n",
    "        # In[25]:\n",
    "\n",
    "\n",
    "        # ARTS forward model with the LDAPS data.\n",
    "        # Save the LDAPS variables as the input atmopsheric profiles. \n",
    "\n",
    "        # Save pressure grid as .xml files.\n",
    "        tp.arts.xml.save(LDAPS_p, './ClearSky_1D_p_grid.xml')\n",
    "\n",
    "        # Save z_field as GriddedField3 xml file. \n",
    "        z_field_GF3 = tp.arts.griddedfield.GriddedField3()\n",
    "        z_field_GF3.data = np.reshape(LDAPS_z,(len(LDAPS_p),1,1))\n",
    "        z_field_GF3.grids = [LDAPS_p, np.array([0]), np.array([0])]\n",
    "        z_field_GF3.gridnames = ['Pressure', 'Latitude', 'Longitude']\n",
    "        tp.arts.xml.save(z_field_GF3, './ClearSky_1D.z.xml')\n",
    "\n",
    "        # Save t_field as GriddedField3 xml file. \n",
    "        # Remove temperature values greater than 300 K, due to partition functions error in ARTS. \n",
    "        # LDAPS_t[LDAPS_t > 300] = 300\n",
    "        t_field_GF3 = tp.arts.griddedfield.GriddedField3()\n",
    "        t_field_GF3.data = np.reshape(LDAPS_t,(len(LDAPS_p),1,1))\n",
    "        t_field_GF3.grids = [LDAPS_p, np.array([0]), np.array([0])]\n",
    "        t_field_GF3.gridnames = ['Pressure', 'Latitude', 'Longitude']\n",
    "        tp.arts.xml.save(t_field_GF3, './ClearSky_1D.t.xml')\n",
    "\n",
    "        # Save Water VMR as GriddedField3 xml file. \n",
    "        VMR_H2O_GF3 = tp.arts.griddedfield.GriddedField3()\n",
    "        VMR_H2O_GF3.data = np.reshape(LDAPS_watervmr,(len(LDAPS_p),1,1))\n",
    "        VMR_H2O_GF3.grids = [LDAPS_p, np.array([0]), np.array([0])]\n",
    "        VMR_H2O_GF3.gridnames = ['Pressure', 'Latitude', 'Longitude']\n",
    "        tp.arts.xml.save(VMR_H2O_GF3, './ClearSky_1D.H2O.xml')\n",
    "\n",
    "        # Run ARTS. \n",
    "        tp.arts.run_arts(controlfile='./ClearSky_1D_ARTSvdev.arts');\n",
    "\n",
    "        # ARTS forward model results. \n",
    "        Tb_LDAPS = tp.arts.xml.load(\"./ClearSky_1D_Tb.xml\")\n",
    "\n",
    "\n",
    "        # In[26]:\n",
    "\n",
    "\n",
    "        # Compare brightness temperatures between the radiometer observations, the LDAPS simulations, and the radiosonde simulations. \n",
    "        plt.figure()\n",
    "        plt.plot(radmtr_channels, Tb_radsnd, 'ro', \n",
    "                 radmtr_channels, Tb_LDAPS, 'g^', \n",
    "                 radmtr_channels, BosungObs_radmtr, 'bs')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('Brightness Temperature (K)')\n",
    "        plt.legend(['Radiosonde simulations', 'LDAPS simulations', 'Radiometer bbservations'])\n",
    "        plt.gcf().set_size_inches(15,5)\n",
    "\n",
    "        # Save the figure.\n",
    "        plt.savefig(TimeOfInterest.strftime('%Y_%m_%d_%H-%M-%S_') + 'ForwardModels_v_Observations' + '.png')\n",
    "\n",
    "\n",
    "        # In[27]:\n",
    "\n",
    "\n",
    "        # Plot the difference between the two. \n",
    "        plt.figure()\n",
    "        plt.plot(radmtr_channels, np.zeros(radmtr_channels.shape),'k--', \n",
    "                radmtr_channels, Tb_radsnd - BosungObs_radmtr, 'md', \n",
    "                radmtr_channels, Tb_LDAPS - BosungObs_radmtr, 'cd')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('Brightness Temperature (K)')\n",
    "        plt.legend(['Zero line', 'Radiosonde simulations minus radiometer observations', 'LDAPS simulations minus radiometer observations'])\n",
    "        plt.gcf().set_size_inches(15,5)\n",
    "\n",
    "        # Save the figure.\n",
    "        plt.savefig(TimeOfInterest.strftime('%Y_%m_%d_%H-%M-%S_') + 'ForwardModels_v_Observations_Diff' + '.png')\n",
    "        \n",
    "        # Close all figures at the iteration. \n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in ['03', '04', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16']:\n",
    "    for hour in ['00', '03', '06', '09', '12', '15', '18', '21']:\n",
    "\n",
    "        # In[5]:\n",
    "\n",
    "\n",
    "        # Data month and day\n",
    "        dada = '07-' + day\n",
    "\n",
    "        # Data hour of day\n",
    "        daho = hour\n",
    "\n",
    "        # Files location\n",
    "        dain = os.path.join(os.getcwd(),dada)\n",
    "\n",
    "        # Observation/simulation time\n",
    "        TimeOfInterest = pd.Timestamp('2018-' + dada + ' ' + daho + ':00:00+0000',tz='UTC')\n",
    "\n",
    "\n",
    "        # In[7]:\n",
    "\n",
    "\n",
    "        # Read in brightness temperature data, contained in Level1 data.\n",
    "        f_radmtr_lv1 = glob.glob(dain + '/*lv1.csv')[0]\n",
    "        df_radmtr_lv1 = radiometrics()\n",
    "        df_radmtr_lv1.read_lv1_data(f_radmtr_lv1)\n",
    "\n",
    "        # Radiometer channels\n",
    "        radmtr_channels = df_radmtr_lv1.df.loc[:,'Ch22.000':'Ch58.800'].dropna(axis=1).columns.str.replace('Ch','')\n",
    "        radmtr_channels = radmtr_channels.values.astype(np.float64) * 1e9\n",
    "\n",
    "\n",
    "        # In[8]:\n",
    "\n",
    "\n",
    "        # Radiometer observations (brightness temperatures) for the specific time \n",
    "        BosungObs_radmtr = df_radmtr_lv1.df.loc[(df_radmtr_lv1.df.DateTime - TimeOfInterest).abs().idxmin()]\n",
    "        print(BosungObs_radmtr.DateTime)\n",
    "        BosungObs_radmtr = BosungObs_radmtr.loc['Ch22.000':'Ch58.800'].dropna().values.flatten()\n",
    "\n",
    "\n",
    "        # In[9]:\n",
    "\n",
    "\n",
    "        # Save as .xml files. \n",
    "        tp.arts.xml.save(radmtr_channels, './ClearSky_1D_f_grid.xml')\n",
    "        tp.arts.xml.save(BosungObs_radmtr, './BosungObservations.xml')\n",
    "\n",
    "\n",
    "        # In[10]:\n",
    "\n",
    "\n",
    "        # Bosung radiometer's Gaussian optical antenna characteristics. \n",
    "\n",
    "        # Full width at half maximum:\n",
    "        FWHM_22GHz = 6.3 ;\n",
    "        FWHM_30GHz = 4.9 ;\n",
    "        FWHM_51GHz = 2.5 ;\n",
    "        FWHM_59GHz = 2.4 ;\n",
    "        # Linear interpolation\n",
    "        FWHM_22to30GHz = np.interp(radmtr_channels[0:8], np.array([22, 30])*1e9, [FWHM_22GHz, FWHM_30GHz]) ;\n",
    "        FWHM_51to59GHz = np.interp(radmtr_channels[8:22], np.array([51, 59])*1e9, [FWHM_51GHz, FWHM_59GHz]) ;\n",
    "        FWHM = np.append(FWHM_22to30GHz, FWHM_51to59GHz)\n",
    "\n",
    "        # Antenna response\n",
    "        xwidth_si = 3; # Default value in ARTS. See \"antenna_responseGaussian\".\n",
    "        dx_si = 0.1; # Default values in ARTS. See \"antenna_responseGaussian\".\n",
    "        Zenith_angle = np.arange(-xwidth_si, xwidth_si + dx_si, dx_si) * FWHM_22GHz / (2*(2*np.log(2))**0.5)\n",
    "        anthenna_response = np.zeros((1, len(radmtr_channels), len(Zenith_angle), 1))\n",
    "        for i in range(len(radmtr_channels)):\n",
    "            std_FWHM = FWHM[i]/(2*(2*np.log(2))**0.5)\n",
    "            anthenna_response[0,i,:,0] = 1/(std_FWHM*(2*np.pi)**0.5)*np.exp(-4*np.log(2)*Zenith_angle**2/(FWHM[i]**2))\n",
    "\n",
    "        # Define ARTS variable \"mblock_dlos_grid\". \n",
    "        mblock_dlos_grid = np.array([np.linspace(Zenith_angle[0],Zenith_angle[len(Zenith_angle)-1],20)]).T\n",
    "\n",
    "\n",
    "        # In[11]:\n",
    "\n",
    "\n",
    "        # Save antenna_response as GriddedField4 .xml file. \n",
    "        antenna_response_GF4 = tp.arts.griddedfield.GriddedField4()\n",
    "        antenna_response_GF4.name = 'Antenna response'\n",
    "        antenna_response_GF4.data = anthenna_response\n",
    "        antenna_response_GF4.grids = [['NaN'], radmtr_channels, Zenith_angle, np.array([0])]\n",
    "        antenna_response_GF4.gridnames = ['Polarisation', 'Frequency', 'Zenith angle', 'Azimuth angle']\n",
    "        tp.arts.xml.save(antenna_response_GF4, './ClearSky_1D_antenna_response.xml')\n",
    "\n",
    "        # Save mblock_dlos_grid as .xml file. \n",
    "        tp.arts.xml.save(mblock_dlos_grid, './ClearSky_1D_mblock_dlos_grid.xml')\n",
    "\n",
    "\n",
    "        # In[12]:\n",
    "\n",
    "\n",
    "        # Sensor LOS and geolocation \n",
    "        tp.arts.xml.save(np.array([[0]]), './ClearSky_1D_sensor_los.xml')\n",
    "        tp.arts.xml.save(np.array([[0]]), './ClearSky_1D_sensor_pos.xml')\n",
    "\n",
    "\n",
    "        # In[13]:\n",
    "\n",
    "\n",
    "        # Read in LDAPS data. \n",
    "\n",
    "        # Pressure (pres) data\n",
    "        fn_pres = \"ldps_v070_erlo_pres_BSWO_h000.\" + TimeOfInterest.strftime('%Y%m%d%H') + \".txt\"\n",
    "        f_pres = os.path.join(dain,fn_pres)\n",
    "        df_pres = pd.read_csv(f_pres, skiprows=0, \n",
    "                         names=['Index', '?(GridPosition)', 'Type', 'Pressure', 'Longitude', 'Latitude', 'Value'], \n",
    "                         sep=' mb:lon=|,lat=|,val=|:', \n",
    "                         engine='python')\n",
    "        pres_P = df_pres.loc[df_pres.Type=='HGT'].Pressure.values * 100\n",
    "        pres_GH = df_pres.loc[df_pres.Type=='HGT'].Value.values\n",
    "        pres_T = df_pres.loc[df_pres.Type=='TMP'].Value.values\n",
    "        pres_RH = df_pres.loc[df_pres.Type=='RH'].Value.values\n",
    "        pres_Lat = df_pres.Latitude[0]\n",
    "\n",
    "        # Surface (unis) data\n",
    "        fn_unis = \"ldps_v070_erlo_unis_BSWO_h000.\" + TimeOfInterest.strftime('%Y%m%d%H') + \".txt\"\n",
    "        f_unis = os.path.join(dain,fn_unis)\n",
    "        df_unis = pd.read_csv(f_unis, skiprows=0, \n",
    "                         names=['Index', '?(GridPosition)', 'Type', 'Altitude', 'Longitude', 'Latitude', 'Value'], \n",
    "                         sep=':lon=|,lat=|,val=|:',\n",
    "                         engine='python')\n",
    "        unis_P = df_unis.loc[df_unis.Type=='PRMSL'].Value.values # df_unis.loc[df_unis.Type=='PRES'].Value.values\n",
    "        unis_T = df_unis.loc[(df_unis.Type=='TMP') & (df_unis.Altitude=='surface')].Value.values\n",
    "        unis_RH = df_unis.loc[df_unis.Type=='RH'].Value.values\n",
    "        unis_Alt = 0 # df_unis.loc[df_unis.Type=='DIST'].Value.values\n",
    "\n",
    "\n",
    "        # In[14]:\n",
    "\n",
    "\n",
    "        # Pressure\n",
    "\n",
    "        # Combine the unis and pres variables. \n",
    "        LDAPS_p = np.append(unis_P, pres_P)\n",
    "        LDAPS_p\n",
    "\n",
    "\n",
    "        # In[15]:\n",
    "\n",
    "\n",
    "        # Altitude\n",
    "\n",
    "        # Convert geopotential height to geometric height. \n",
    "        # Reference (accessed 2018-07-02): \n",
    "        # http://glossary.ametsoc.org/wiki/Geopotential_height\n",
    "        # http://glossary.ametsoc.org/wiki/Acceleration_of_gravity \n",
    "        g0 = 9.80665 # Standard gravity at sea level \n",
    "        g_lat = 0.01*(980.6160*(\n",
    "            1 - 0.0026373*np.cos(np.pi/180 * 2*pres_Lat) + 0.0000059*(\n",
    "                np.cos(np.pi/180 * 2*pres_Lat)**2))) # Sea-level gravity at given latitude\n",
    "        Cg = 0.01*(3.085462*(10**-4) + 2.27*(10**-7)*np.cos(np.pi/180*2*pres_Lat)) # The coefficient in the gravity equation. \n",
    "\n",
    "        # Solve for geometric height, using the quadratic formula.\n",
    "        a = Cg/2\n",
    "        b = -g_lat\n",
    "        c = g0*pres_GH\n",
    "        pres_Alt = (-b - (b**2 - 4*a*c)**0.5)/(2*a)\n",
    "        # Here, the geopotential height is given based on 국지예보모델, so the calculated z field may be based on a spherical coordinates system.\n",
    "        # ARTS requires z field that is defined in terms of the geometrical altitude, \n",
    "        # which is the distance between the ellipsoid's surface and the point along the line passing through the Earth's center and the point. \n",
    "        # For now, assume that the difference between the two systems in this regard is negligible. \n",
    "\n",
    "        # Combine the unis and pres variables. \n",
    "        LDAPS_z = np.append(unis_Alt, pres_Alt)\n",
    "        LDAPS_z\n",
    "\n",
    "\n",
    "        # In[16]:\n",
    "\n",
    "\n",
    "        # Temperature\n",
    "\n",
    "        # Combine the unis and pres variables.\n",
    "        LDAPS_t = np.append(unis_T, pres_T)\n",
    "        LDAPS_t\n",
    "\n",
    "\n",
    "        # In[17]:\n",
    "\n",
    "\n",
    "        # Water VMR\n",
    "\n",
    "        # Combine the unis and pres variables.\n",
    "        LDAPS_RH = np.append(unis_RH, pres_RH)\n",
    "\n",
    "        # Convert RH to VMR. \n",
    "        LDAPS_watervmr = tp.physics.relative_humidity2vmr(LDAPS_RH * 0.01, LDAPS_p, LDAPS_t)\n",
    "        LDAPS_watervmr\n",
    "\n",
    "\n",
    "        # In[18]:\n",
    "\n",
    "\n",
    "        # Get rid of invalid values at the pressure levels higher than the surface pressure. \n",
    "        flag_validpressurelevels = (LDAPS_p <= LDAPS_p[0])\n",
    "        LDAPS_p = LDAPS_p[flag_validpressurelevels]\n",
    "        LDAPS_z = LDAPS_z[flag_validpressurelevels]\n",
    "        LDAPS_t = LDAPS_t[flag_validpressurelevels]\n",
    "        LDAPS_watervmr = LDAPS_watervmr[flag_validpressurelevels]\n",
    "\n",
    "\n",
    "        # In[19]:\n",
    "\n",
    "\n",
    "        # Read in radiosondes data. \n",
    "\n",
    "        fn_radsnd = \"UPP_LV2_RS92-SGP_47258_\" + TimeOfInterest.strftime('%Y%m%d%H%M') + \".txt\"\n",
    "        f_radsnd = os.path.join(dain,fn_radsnd)\n",
    "        df_radsnd = pd.read_csv(f_radsnd, sep=\",\")\n",
    "        #print(*df_radsnd.time.values, sep='\\n') # Print all values.\n",
    "        #print(df_radsnd.columns) % Data types. \n",
    "        #print(df_radsnd.loc[1865:1868]) # Pressure duplicates\n",
    "\n",
    "        # Solicit useful variables. \n",
    "        df_radsnd_useful = df_radsnd[['HGT', 'time', 'P', 'Temp', 'RH', 'MixR', 'Lon', 'Lat', 'Alt']]\n",
    "        df_radsnd_useful = df_radsnd_useful.dropna().reset_index().drop('index',axis=1)\n",
    "        df_radsnd_useful.loc[1:,] = df_radsnd_useful.loc[1:,].astype(float).values \n",
    "        df_radsnd_useful_size = len(df_radsnd_useful.loc[:,'P'])\n",
    "\n",
    "\n",
    "        # In[20]:\n",
    "\n",
    "\n",
    "        # Interpolate the data to fewer vertical grids. Use the nearest neighbor interpolation.\n",
    "        df_radsnd_useful_interp_size = 50;\n",
    "        df_radsnd_useful_interp = pd.DataFrame( \n",
    "            {'P' : \n",
    "             np.linspace(df_radsnd_useful.loc[1,'P'], df_radsnd_useful.loc[df_radsnd_useful_size-1,'P'], df_radsnd_useful_interp_size)} )\n",
    "        df_radsnd_useful_interp = df_radsnd_useful_interp.reindex(df_radsnd_useful.columns, axis=1)\n",
    "\n",
    "        # Interpolation\n",
    "        for i in range(df_radsnd_useful_interp_size):\n",
    "            nearneigindex = (df_radsnd_useful.loc[1:,'P'] - df_radsnd_useful_interp.loc[i,'P']).astype(float).abs().idxmin()\n",
    "            df_radsnd_useful_interp.loc[i,] = df_radsnd_useful.loc[nearneigindex,].astype('float')\n",
    "\n",
    "        # Unit conversions\n",
    "        df_radsnd_useful_interp.loc[:,'P'] = df_radsnd_useful_interp.loc[:,'P'] * 100\n",
    "        df_radsnd_useful_interp.loc[:,'Temp'] = df_radsnd_useful_interp.loc[:,'Temp'] + 273.15\n",
    "        df_radsnd_useful_interp.loc[:,'RH'] = df_radsnd_useful_interp.loc[:,'RH'] * 1e-2\n",
    "\n",
    "\n",
    "        # In[21]:\n",
    "\n",
    "\n",
    "        # Necessary variables for ARTS simulations \n",
    "        radsnd_P = df_radsnd_useful_interp.loc[:,'P'].values\n",
    "        radsnd_T = df_radsnd_useful_interp.loc[:,'Temp'].values\n",
    "        radsnd_WaterVMR = tp.physics.relative_humidity2vmr(df_radsnd_useful_interp.loc[:,'RH'].values, radsnd_P, radsnd_T)\n",
    "        radsnd_HGT = df_radsnd_useful_interp.loc[:,'HGT'].values\n",
    "\n",
    "\n",
    "        # In[23]:\n",
    "\n",
    "\n",
    "        # Visualize the LDAPS and radiosondes data. \n",
    "        plt.figure()\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(radsnd_T, radsnd_HGT, LDAPS_t, LDAPS_z)\n",
    "        plt.xlabel('Temperature (K)')\n",
    "        plt.ylabel('Altitude (m)')\n",
    "        #plt.ylabel('Pressure (Pa)')\n",
    "        #plt.gca().invert_yaxis()\n",
    "        plt.legend(['Radiosonde Temperature', 'LDAPS Temperature'])\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(radsnd_WaterVMR, radsnd_HGT, LDAPS_watervmr, LDAPS_z)\n",
    "        plt.xlabel('Volume mixing ratio')\n",
    "        plt.ylabel('Altitude (m)')\n",
    "        #plt.ylabel('Pressure (Pa)')\n",
    "        #plt.gca().invert_yaxis()\n",
    "        plt.legend(['Radiosonde Water VMR', 'LDAPS Water VMR'])\n",
    "\n",
    "        plt.gcf().set_size_inches(16,10)\n",
    "\n",
    "        # Save the figure.\n",
    "        plt.savefig(TimeOfInterest.strftime('%Y_%m_%d_%H-%M-%S_') + 'T&WaterVMR' + '.png')\n",
    "\n",
    "\n",
    "        # In[24]:\n",
    "\n",
    "\n",
    "        # ARTS forward model with the radiosonde data.\n",
    "        # Save the radiosonde variables as the input atmopsheric profiles. \n",
    "\n",
    "        # Save pressure grid as .xml files.\n",
    "        tp.arts.xml.save(radsnd_P, './ClearSky_1D_p_grid.xml')\n",
    "\n",
    "        # Save z_field as GriddedField3 xml file. \n",
    "        z_field_GF3 = tp.arts.griddedfield.GriddedField3()\n",
    "        z_field_GF3.data = np.reshape(radsnd_HGT,(len(radsnd_P),1,1))\n",
    "        z_field_GF3.grids = [radsnd_P, np.array([0]), np.array([0])]\n",
    "        z_field_GF3.gridnames = ['Pressure', 'Latitude', 'Longitude']\n",
    "        tp.arts.xml.save(z_field_GF3, './ClearSky_1D.z.xml')\n",
    "\n",
    "        # Save t_field as GriddedField3 xml file. \n",
    "        # Remove temperature values greater than 300 K, due to partition functions error in ARTS. \n",
    "        # radsnd_T[radsnd_T > 300] = 300\n",
    "        t_field_GF3 = tp.arts.griddedfield.GriddedField3()\n",
    "        t_field_GF3.data = np.reshape(radsnd_T,(len(radsnd_P),1,1))\n",
    "        t_field_GF3.grids = [radsnd_P, np.array([0]), np.array([0])]\n",
    "        t_field_GF3.gridnames = ['Pressure', 'Latitude', 'Longitude']\n",
    "        tp.arts.xml.save(t_field_GF3, './ClearSky_1D.t.xml')\n",
    "\n",
    "        # Save Water VMR as GriddedField3 xml file. \n",
    "        VMR_H2O_GF3 = tp.arts.griddedfield.GriddedField3()\n",
    "        VMR_H2O_GF3.data = np.reshape(radsnd_WaterVMR,(len(radsnd_P),1,1))\n",
    "        VMR_H2O_GF3.grids = [radsnd_P, np.array([0]), np.array([0])]\n",
    "        VMR_H2O_GF3.gridnames = ['Pressure', 'Latitude', 'Longitude']\n",
    "        tp.arts.xml.save(VMR_H2O_GF3, './ClearSky_1D.H2O.xml')\n",
    "\n",
    "        # Run ARTS. \n",
    "        tp.arts.run_arts(controlfile='./ClearSky_1D_ARTSvdev.arts');\n",
    "\n",
    "        # ARTS forward model results. \n",
    "        Tb_radsnd = tp.arts.xml.load(\"./ClearSky_1D_Tb.xml\")\n",
    "\n",
    "\n",
    "        # In[25]:\n",
    "\n",
    "\n",
    "        # ARTS forward model with the LDAPS data.\n",
    "        # Save the LDAPS variables as the input atmopsheric profiles. \n",
    "\n",
    "        # Save pressure grid as .xml files.\n",
    "        tp.arts.xml.save(LDAPS_p, './ClearSky_1D_p_grid.xml')\n",
    "\n",
    "        # Save z_field as GriddedField3 xml file. \n",
    "        z_field_GF3 = tp.arts.griddedfield.GriddedField3()\n",
    "        z_field_GF3.data = np.reshape(LDAPS_z,(len(LDAPS_p),1,1))\n",
    "        z_field_GF3.grids = [LDAPS_p, np.array([0]), np.array([0])]\n",
    "        z_field_GF3.gridnames = ['Pressure', 'Latitude', 'Longitude']\n",
    "        tp.arts.xml.save(z_field_GF3, './ClearSky_1D.z.xml')\n",
    "\n",
    "        # Save t_field as GriddedField3 xml file. \n",
    "        # Remove temperature values greater than 300 K, due to partition functions error in ARTS. \n",
    "        # LDAPS_t[LDAPS_t > 300] = 300\n",
    "        t_field_GF3 = tp.arts.griddedfield.GriddedField3()\n",
    "        t_field_GF3.data = np.reshape(LDAPS_t,(len(LDAPS_p),1,1))\n",
    "        t_field_GF3.grids = [LDAPS_p, np.array([0]), np.array([0])]\n",
    "        t_field_GF3.gridnames = ['Pressure', 'Latitude', 'Longitude']\n",
    "        tp.arts.xml.save(t_field_GF3, './ClearSky_1D.t.xml')\n",
    "\n",
    "        # Save Water VMR as GriddedField3 xml file. \n",
    "        VMR_H2O_GF3 = tp.arts.griddedfield.GriddedField3()\n",
    "        VMR_H2O_GF3.data = np.reshape(LDAPS_watervmr,(len(LDAPS_p),1,1))\n",
    "        VMR_H2O_GF3.grids = [LDAPS_p, np.array([0]), np.array([0])]\n",
    "        VMR_H2O_GF3.gridnames = ['Pressure', 'Latitude', 'Longitude']\n",
    "        tp.arts.xml.save(VMR_H2O_GF3, './ClearSky_1D.H2O.xml')\n",
    "\n",
    "        # Run ARTS. \n",
    "        tp.arts.run_arts(controlfile='./ClearSky_1D_ARTSvdev.arts');\n",
    "\n",
    "        # ARTS forward model results. \n",
    "        Tb_LDAPS = tp.arts.xml.load(\"./ClearSky_1D_Tb.xml\")\n",
    "\n",
    "\n",
    "        # In[26]:\n",
    "\n",
    "\n",
    "        # Compare brightness temperatures between the radiometer observations, the LDAPS simulations, and the radiosonde simulations. \n",
    "        plt.figure()\n",
    "        plt.plot(radmtr_channels, Tb_radsnd, 'ro', \n",
    "                 radmtr_channels, Tb_LDAPS, 'g^', \n",
    "                 radmtr_channels, BosungObs_radmtr, 'bs')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('Brightness Temperature (K)')\n",
    "        plt.legend(['Radiosonde simulations', 'LDAPS simulations', 'Radiometer bbservations'])\n",
    "        plt.gcf().set_size_inches(15,5)\n",
    "\n",
    "        # Save the figure.\n",
    "        plt.savefig(TimeOfInterest.strftime('%Y_%m_%d_%H-%M-%S_') + 'ForwardModels_v_Observations' + '.png')\n",
    "\n",
    "\n",
    "        # In[27]:\n",
    "\n",
    "\n",
    "        # Plot the difference between the two. \n",
    "        plt.figure()\n",
    "        plt.plot(radmtr_channels, np.zeros(radmtr_channels.shape),'k--', \n",
    "                radmtr_channels, Tb_radsnd - BosungObs_radmtr, 'md', \n",
    "                radmtr_channels, Tb_LDAPS - BosungObs_radmtr, 'cd')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('Brightness Temperature (K)')\n",
    "        plt.legend(['Zero line', 'Radiosonde simulations minus radiometer observations', 'LDAPS simulations minus radiometer observations'])\n",
    "        plt.gcf().set_size_inches(15,5)\n",
    "\n",
    "        # Save the figure.\n",
    "        plt.savefig(TimeOfInterest.strftime('%Y_%m_%d_%H-%M-%S_') + 'ForwardModels_v_Observations_Diff' + '.png')\n",
    "        \n",
    "        # Close all figures at the iteration. \n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
